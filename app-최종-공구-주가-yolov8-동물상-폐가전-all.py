# app.py (í†µí•© ë° ë””ë²„ê¹… ê°•í™” ë²„ì „)

import os
import io
import uuid
import threading
import traceback  # ğŸ‘ˆ ìƒì„¸ ì—ëŸ¬ ì¶œë ¥ì„ ìœ„í•´ ì¶”ê°€

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
from flask import Flask, request, jsonify, render_template, url_for, send_from_directory
from flask_cors import CORS
from PIL import Image
import cv2
from werkzeug.utils import secure_filename
from ultralytics import YOLO
import numpy as np
import pandas as pd

# ==============================================================================
# 1. Flask ì•± ë° ê¸°ë³¸ ì„¤ì •
# ==============================================================================
app = Flask(__name__)
CORS(app)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… Using device: {device}")

UPLOAD_FOLDER = 'uploads'
RESULT_FOLDER = 'results'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)


# ==============================================================================
# 2. ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
# ==============================================================================
class StockPredictorRNN(nn.Module):
    def __init__(self, input_size=4, hidden_size=64, num_layers=1, output_size=1):
        super(StockPredictorRNN, self).__init__()
        self.hidden_size = hidden_size  # ğŸ‘ˆ ì´ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”.
        self.num_layers = num_layers  # ğŸ‘ˆ ì´ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”.
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.rnn(x, h0)
        return self.fc(out[:, -1, :])


class LSTMModel(nn.Module):
    def __init__(self, input_size=4, hidden_size=128, output_size=1, num_layers=2, dropout=0.3):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        last_out = lstm_out[:, -1, :]
        return self.fc(self.relu(last_out))


class GRUModel(nn.Module):
    def __init__(self, input_size=4, hidden_size=64, num_layers=1, output_size=1):
        super(GRUModel, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.gru(x)
        return self.fc(out[:, -1])


# ==============================================================================
# 3. ëª¨ë“  ëª¨ë¸ ë° ë°ì´í„° ë¡œë”©
# ==============================================================================

# --- ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì • (ìš”ì²­ ì‹œ ë¡œë“œ) ---
MODEL_CONFIGS = {
    "team1": {"model_path": "./resnet50_best_team1_animal.pth", "num_classes": 5,
              "class_labels": ["ê³ ì–‘ì´", "ê³µë£¡", "ê°•ì•„ì§€", "ê¼¬ë¶ì´", "í‹°ë²³ì—¬ìš°"]},
    "team2": {"model_path": "./resnet50_best_team2_recycle.pth", "num_classes": 13,
              "class_labels": ["ì˜ì—…ìš©_ëƒ‰ì¥ê³ ", "ì»´í“¨í„°_cpu", "ë“œëŸ¼_ì„¸íƒê¸°", "ëƒ‰ì¥ê³ ", "ì»´í“¨í„°_ê·¸ë˜í”½ì¹´ë“œ", "ë©”ì¸ë³´ë“œ", "ì „ìë ˆì¸ì§€", "ì»´í“¨í„°_íŒŒì›Œ", "ì»´í“¨í„°_ë¨",
                               "ìŠ¤íƒ ë“œ_ì—ì–´ì»¨", "TV", "ë²½ê±¸ì´_ì—ì–´ì»¨", "í†µëŒì´_ì„¸íƒê¸°"]},
    "team3": {"model_path": "./resnet50_best_team3_tools_accuracy_90.pth", "num_classes": 10,
              "class_labels": ["ê³µêµ¬ í†±", "ê³µì—…ìš©ê°€ìœ„", "ê·¸ë¼ì¸ë”", "ë‹ˆí¼", "ë“œë¼ì´ë²„", "ë§ì¹˜", "ìŠ¤íŒ¨ë„ˆ", "ì „ë™ë“œë¦´", "ì¤„ì", "ìº˜ë¦¬í¼ìŠ¤"]},
}

# --- YOLO ëª¨ë¸ ë¡œë“œ (ì‹œì‘ ì‹œ ë¡œë“œ) ---
try:
    yolo_model = YOLO("best-busanit501-aqua.pt")
    print("âœ… YOLO model loaded successfully.")
except Exception as e:
    print(f"ğŸ”´ ERROR loading YOLO model: {e}")
    yolo_model = None

# --- ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ (ì‹œì‘ ì‹œ ë¡œë“œ) ---
stock_models = {}
stock_scalers = {}

try:
    stock_models['RNN'] = StockPredictorRNN().to(device)
    stock_models['RNN'].load_state_dict(torch.load('Rnn-samsungStock.pth', map_location=device))
    stock_models['RNN'].eval()
    stock_scalers['RNN'] = torch.load('Rnn-scaler.pth', map_location=device)

    stock_models['LSTM'] = LSTMModel().to(device)
    stock_models['LSTM'].load_state_dict(torch.load('samsungStock_LSTM_60days_basic.pth', map_location=device))
    stock_models['LSTM'].eval()
    stock_scalers['LSTM'] = torch.load('scaler_LSTM_60days_basic.pth', map_location=device)

    stock_models['GRU'] = GRUModel().to(device)
    stock_models['GRU'].load_state_dict(torch.load('samsungStock_GRU.pth', map_location=device))
    stock_models['GRU'].eval()
    stock_scalers['GRU'] = torch.load('scaler_GRU.pth', map_location=device)
    print("âœ… Stock prediction models and scalers loaded successfully.")
except FileNotFoundError as e:
    print(f"ğŸ”´ ERROR: Stock model or scaler file not found: {e.filename}")
except Exception as e:
    print(f"ğŸ”´ ERROR loading stock models: {e}")

try:
    stock_df = pd.read_csv('7-samsung_stock_2022_01_2025_10_13.csv', index_col='Date', parse_dates=True)
    stock_df.sort_index(inplace=True)
    print("âœ… Stock data CSV loaded successfully.")
except FileNotFoundError:
    print("ğŸ”´ ERROR: '7-samsung_stock_2022_01_2025_10_13.csv' not found.")
    stock_df = None


# ==============================================================================
# 4. í—¬í¼ í•¨ìˆ˜ (YOLO ì²˜ë¦¬, ëª¨ë¸ ë¡œë“œ)
# ==============================================================================

def process_yolo(file_path, output_path, file_type):
    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼, ìƒëµ) ...
    try:
        if file_type == 'image':
            results = yolo_model(file_path)
            result_img = results[0].plot()
            cv2.imwrite(output_path, result_img)

        elif file_type == 'video':
            temp_output_path = output_path + ".tmp"
            cap = cv2.VideoCapture(file_path)
            if not cap.isOpened():
                print(f"ğŸ”´ ERROR: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                return

            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))

            if fps <= 0:
                fps = 30
                print(f"âš ï¸ WARNING: FPSë¥¼ ê°ì§€í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ {fps}ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")

            codecs_to_try = [('mp4v', '.mp4'), ('XVID', '.avi'), ('MJPG', '.avi')]
            out = None
            for codec, ext in codecs_to_try:
                try:
                    fourcc = cv2.VideoWriter_fourcc(*codec)
                    if not temp_output_path.endswith(ext):
                        temp_output_path = os.path.splitext(temp_output_path)[0] + ext
                        output_path = os.path.splitext(output_path)[0] + ext
                    out = cv2.VideoWriter(temp_output_path, fourcc, fps, (width, height))
                    if out.isOpened():
                        print(f"âœ… VideoWriter ì´ˆê¸°í™” ì„±ê³µ: ì½”ë±={codec}, í•´ìƒë„={width}x{height}, FPS={fps}")
                        break
                    else:
                        out.release()
                        out = None
                except Exception as e:
                    print(f"âš ï¸ {codec} ì½”ë± ì˜¤ë¥˜: {e}")
                    continue

            if out is None or not out.isOpened():
                print(f"ğŸ”´ ERROR: ëª¨ë“  ì½”ë± ì‹œë„ ì‹¤íŒ¨. OpenCV ë¹„ë””ì˜¤ ì¶œë ¥ì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                cap.release()
                return

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                results = yolo_model(frame)
                result_frame = results[0].plot()
                out.write(result_frame)

            cap.release()
            out.release()

            if os.path.exists(temp_output_path):
                os.rename(temp_output_path, output_path)
                print(f"âœ… YOLO ì²˜ë¦¬ ì™„ë£Œ: {output_path}")
            else:
                print(f"ğŸ”´ ERROR: ì„ì‹œ íŒŒì¼({temp_output_path})ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸ”´ ERROR in process_yolo thread: {e}")


def load_classification_model(model_type):
    config = MODEL_CONFIGS[model_type]
    model = models.resnet50(pretrained=False)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, config["num_classes"])
    model.load_state_dict(torch.load(config["model_path"], map_location=device))
    model.to(device)
    model.eval()
    return model, config["class_labels"]


# ==============================================================================
# 5. Flask ë¼ìš°íŠ¸ (API ì—”ë“œí¬ì¸íŠ¸)
# ==============================================================================

@app.route("/")
def index():
    return render_template('index.html')


# --- ì´ë¯¸ì§€/YOLO ì²˜ë¦¬ API ---
@app.route("/predict/<model_type>", methods=["POST"])
def predict(model_type):
    if "image" not in request.files:
        return jsonify({"error": "ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
    file = request.files["image"]
    if file.filename == "":
        return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

    if model_type == 'yolo':
        # ... (YOLO ì²˜ë¦¬ ë¡œì§, ê¸°ì¡´ê³¼ ë™ì¼) ...
        original_filename = file.filename
        filename_base, file_extension = os.path.splitext(original_filename)

        if file_extension.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
            file_type = 'image'
        elif file_extension.lower() in ['.mp4', '.avi', '.mov', '.mkv']:
            file_type = 'video'
        else:
            return jsonify({"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}), 400

        safe_filename_base = secure_filename(filename_base)
        unique_id = str(uuid.uuid4())[:8]
        safe_filename = f"{safe_filename_base}_{unique_id}{file_extension}"
        file_path = os.path.join(UPLOAD_FOLDER, safe_filename)
        file.save(file_path)

        if file_type == 'video':
            output_filename = f"result_{safe_filename_base}_{unique_id}.mp4"
        else:
            output_filename = f"result_{safe_filename}"
        output_path = os.path.join(RESULT_FOLDER, output_filename)

        thread = threading.Thread(target=process_yolo, args=(file_path, output_path, file_type))
        thread.start()

        return jsonify({
            "message": "YOLO ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "output_filename": output_filename,
            "result_url": request.host_url.rstrip('/') + url_for('serve_result', filename=output_filename),
            "status_url": request.host_url.rstrip('/') + url_for('get_status', filename=output_filename)
        })

    elif model_type in MODEL_CONFIGS:
        try:
            model, class_labels = load_classification_model(model_type)
            image_bytes = file.read()
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
            image_tensor = transform(image).unsqueeze(0).to(device)

            with torch.no_grad():
                outputs = model(image_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                predicted_idx = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_idx].item() * 100

            # ë©”ëª¨ë¦¬ í•´ì œ (ì¤‘ìš”)
            del model, image_tensor, outputs
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            return jsonify({
                "filename": file.filename,
                "predicted_class": class_labels[predicted_idx],
                "confidence": f"{confidence:.2f}%",
            })
        except Exception as e:
            # ğŸ‘ˆ ì—ëŸ¬ ë°œìƒ ì‹œ í„°ë¯¸ë„ì— ìƒì„¸ ë¡œê·¸ ì¶œë ¥
            print(f"ğŸ”´ ERROR in /predict/{model_type}: {e}")
            traceback.print_exc()
            return jsonify({"error": "Internal server error during prediction.", "details": str(e)}), 500
    else:
        return jsonify({"error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ ìœ í˜•: {model_type}"}), 400


@app.route('/status/<filename>')
def get_status(filename):
    if os.path.exists(os.path.join(RESULT_FOLDER, filename)):
        return jsonify({"status": "complete", "url": url_for('serve_result', filename=filename)})
    return jsonify({"status": "processing"})


@app.route('/results/<filename>')
def serve_result(filename):
    return send_from_directory(RESULT_FOLDER, filename)


# --- ì£¼ê°€ ì˜ˆì¸¡ API ---
@app.route('/api/stockdata')
def get_stockdata():
    if stock_df is None:
        return jsonify({"error": "ì„œë²„ì— ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 500
    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼, ìƒëµ) ...
    period = request.args.get('period', '5d')
    df_copy = stock_df.copy()
    df_copy.columns = [col.capitalize() for col in df_copy.columns]
    period_map = {'1d': 1, '5d': 5}
    days = period_map.get(period, 5)
    recent_data = df_copy.tail(days)

    if period == '1d':
        data_subset = recent_data
    else:
        data_subset = recent_data.iloc[:-1]

    data_subset = data_subset.reset_index()
    data_subset['Date'] = data_subset['Date'].dt.strftime('%Y-%m-%d')
    return jsonify(data_subset.to_dict(orient='records'))


@app.route('/api/predict2/<string:model_type>', methods=['POST'])
def predict2(model_type):
    try:
        req_data = request.get_json()
        input_data = req_data.get('data')
        period = req_data.get('period')
        model_key = model_type.upper()

        model = stock_models.get(model_key)
        scaler = stock_scalers.get(model_key)

        if not model or not scaler:
            return jsonify({"error": f"'{model_type}' ëª¨ë¸ì„ ì„œë²„ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        # ... (ë°ì´í„° ê²€ì¦ ë° ì˜ˆì¸¡ ë¡œì§, ê¸°ì¡´ê³¼ ë™ì¼) ...
        input_np = np.array(input_data)
        input_scaled = scaler.transform(input_np)
        input_tensor = torch.Tensor(input_scaled).unsqueeze(0).to(device)

        with torch.no_grad():
            prediction_scaled = model(input_tensor).item()

        prediction = scaler.inverse_transform([[0, 0, 0, prediction_scaled]])[0][3]
        return jsonify({"prediction": round(prediction, 2)})

    except Exception as e:
        print(f"ğŸ”´ ERROR in /api/predict2/{model_type}: {e}")
        traceback.print_exc()
        return jsonify({"error": "ì˜ˆì¸¡ ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500


# ==============================================================================
# 6. Flask ì•± ì‹¤í–‰
# ==============================================================================
if __name__ == '__main__':
    app.run(debug=True, port=5000)